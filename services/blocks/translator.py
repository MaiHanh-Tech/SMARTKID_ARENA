import streamlit as st
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import time
import json
import jieba
from pypinyin import pinyin, Style
from pydantic import BaseModel, Field
from typing import List
from collections import OrderedDict

# ðŸ‘‡ IMPORT Má»šI (Tá»« thÆ° má»¥c blocks)
from services.blocks.config import AppConfig
from services.blocks.logger import AppLogger

class WordDefinition(BaseModel):
    word: str
    pinyin: str
    translation: str

class InteractiveTranslation(BaseModel):
    words: List[WordDefinition]

class Translator:
    _instance = None
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance.initialized = False
        return cls._instance

    def __init__(self):
        if not self.initialized:
            self.logger = AppLogger() # âœ… Khá»Ÿi táº¡o Logger

            # 1. Láº¥y API Key
            self.api_key = st.secrets.get("google_genai", {}).get("api_key", "") or st.secrets.get("api_key", "")
            # Fallback sang key cá»§a AI_Core náº¿u cÃ³
            if not self.api_key and "api_keys" in st.secrets:
                self.api_key = st.secrets["api_keys"].get("gemini_api_key", "")

            if self.api_key: 
                genai.configure(api_key=self.api_key)
            else:
                self.logger.log_error("Translator", "Missing API Key", "")
            
            # 2. Cáº¥u hÃ¬nh Model (âœ… Láº¤Y Tá»ª CONFIG)
            self.model_flash = AppConfig.GEMINI_MODELS["flash"]
            self.model_pro = AppConfig.GEMINI_MODELS["pro"]
            
            # Náº¿u user cáº¥u hÃ¬nh Ä‘Ã¨ trong secrets
            if "google_genai" in st.secrets:
                self.model_flash = st.secrets["google_genai"].get("model_flash", self.model_flash)
                self.model_pro = st.secrets["google_genai"].get("model_pro", self.model_pro)

            self.safety = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE
            }
            
            # âœ… DÃ™NG OrderedDict Vá»šI GIá»šI Háº N
            self.cache = OrderedDict()
            self.MAX_CACHE_SIZE = 100
            
            self.initialized = True

    def _generate(self, model_name, prompt, structured_output=None):
        if not self.api_key: return "Error: ChÆ°a nháº­p API Key"
        
        start_time = time.time() # âœ… Äo thá»i gian
        gen_config = {"temperature": 0.3}
        if structured_output:
            gen_config.update({"response_mime_type": "application/json", "response_schema": structured_output})

        model = genai.GenerativeModel(model_name=model_name, safety_settings=self.safety, generation_config=gen_config)

        # Thá»­ tá»‘i Ä‘a 2 láº§n, chá» ngáº¯n
        for attempt in range(2):
            try:
                response = model.generate_content(prompt)
                if response.text: 
                    # âœ… Ghi Log thÃ nh cÃ´ng
                    latency = time.time() - start_time
                    self.logger.log_api_call(model_name, len(prompt), latency, True)
                    return response.text
            except Exception as e:
                err = str(e)
                self.logger.log_error("Translator_Generate", err, "") # âœ… Ghi Log lá»—i

                # Náº¿u sai model (404)
                if "404" in err or "Not Found" in err:
                    return f"[Model Error: Model {model_name} khÃ´ng tá»“n táº¡i]"
                
                # Náº¿u quÃ¡ táº£i (429) -> Chá» 2s rá»“i thá»­ láº¡i
                if "429" in err or "exhausted" in err:
                    time.sleep(2)
                    continue
                
                return f"[API Error: {err}]"
        
        return "[System Busy: QuÃ¡ táº£i, vui lÃ²ng thá»­ láº¡i sau vÃ i giÃ¢y]"

    def _add_to_cache(self, key, value):
        """ThÃªm vÃ o cache vá»›i giá»›i háº¡n kÃ­ch thÆ°á»›c"""
        if len(self.cache) >= self.MAX_CACHE_SIZE:
            self.cache.popitem(last=False)
        self.cache[key] = value

    def translate_text(self, text, source, target, prompt_template=None):
        if not text.strip(): return ""
        
        cache_key = f"{text[:200]}|{source}|{target}"
        if cache_key in self.cache: 
            return self.cache[cache_key]

        full_prompt = f"{prompt_template}\n\nNguá»“n: {source}\nÄÃ­ch: {target}\nVÄƒn báº£n: {text}"
        
        # LuÃ´n dÃ¹ng Flash trÆ°á»›c
        res = self._generate(self.model_flash, full_prompt)
        
        # Náº¿u Flash lá»—i model, fallback sang config default
        if "Model Error" in res:
            res = self._generate(AppConfig.GEMINI_MODELS["flash"], full_prompt)

        if "API Error" not in res and "System Busy" not in res:
            self._add_to_cache(cache_key, res.strip())
            
        return res.strip()

    def process_word_by_word(self, text, source, target):
        prompt = f"PhÃ¢n tÃ­ch tá»« vá»±ng: '{text}' ({source}->{target})."
        res = self._generate(self.model_flash, prompt, structured_output=InteractiveTranslation)
        try:
            return [w.model_dump() for w in InteractiveTranslation.model_validate_json(res).words]
        except:
            return [{'word': w, 'pinyin': '', 'translations': []} for w in jieba.cut(text)]
