import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import time
from google.api_core.exceptions import ResourceExhausted as GeminiResourceExhausted, ServiceUnavailable as GeminiServiceUnavailable, InternalServerError as GeminiInternalServerError, InvalidArgument as GeminiInvalidArgument
from openai import ResourceExhausted as GrokResourceExhausted, ServiceUnavailable as GrokServiceUnavailable, InternalServerError as GrokInternalServerError, BadRequest as GrokBadRequest

class AI_Core:
    def __init__(self):
        self.gemini_ready = False
        self.grok_ready = False
        self.grok_client = None
        
        # Kh·ªüi t·∫°o Gemini (gi·ªØ nguy√™n nh∆∞ c≈©)
        try:
            if "api_keys" in st.secrets and "gemini_api_key" in st.secrets["api_keys"]:
                gemini_key = st.secrets["api_keys"]["gemini_api_key"]
                genai.configure(api_key=gemini_key)
                
                self.safety_settings = [
                    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
                ]
                
                self.gen_config = genai.GenerationConfig(
                    temperature=0.7,
                    max_output_tokens=4000,
                    top_p=0.95,
                    top_k=40
                )
                
                self.gemini_ready = True
            else:
                st.warning("‚ö†Ô∏è Ch∆∞a c√≥ Gemini API Key")
        except Exception as e:
            st.error(f"‚ùå L·ªói kh·ªüi t·∫°o Gemini: {e}")
        
        # Kh·ªüi t·∫°o Grok
        try:
            if "xai" in st.secrets and "api_key" in st.secrets["xai"]:
                grok_key = st.secrets["xai"]["api_key"]
                self.grok_client = OpenAI(
                    api_key=grok_key,
                    base_url="https://api.x.ai/v1"
                )
                self.grok_ready = True
                st.success("‚úÖ Grok API s·∫µn s√†ng (∆∞u ti√™n d√πng)")
            else:
                st.warning("‚ö†Ô∏è Ch∆∞a c√≥ Grok API Key ‚Üí s·∫Ω fallback Gemini n·∫øu c√≥")
        except Exception as e:
            st.error(f"‚ùå L·ªói kh·ªüi t·∫°o Grok: {e}")

    def _generate_with_gemini(self, prompt, model_type="flash", system_instruction=None):
        """H√†m g·ªçi Gemini (gi·ªØ logic c≈©)"""
        if not self.gemini_ready:
            return None
        
        valid_names = {
            "flash": "gemini-2.0-flash-exp",
            "pro": "gemini-2.0-flash-exp",
        }
        target_name = valid_names.get(model_type, "gemini-2.0-flash-exp")
        
        try:
            model = genai.GenerativeModel(
                model_name=target_name,
                safety_settings=self.safety_settings,
                generation_config=self.gen_config,
                system_instruction=system_instruction
            )
            response = model.generate_content(prompt)
            if response and hasattr(response, 'text') and response.text:
                return response.text
        except (GeminiResourceExhausted, GeminiServiceUnavailable, GeminiInternalServerError, GeminiInvalidArgument) as e:
            return f"Gemini error: {str(e)[:100]}"
        except Exception as e:
            return f"Gemini unknown error: {str(e)[:50]}"
        
        return None

    def _generate_with_grok(self, prompt, model_type="pro", system_instruction=None):
        """H√†m g·ªçi Grok v·ªõi fallback n·ªôi b·ªô model m·∫°nh ‚Üí nh·∫π"""
        if not self.grok_ready or not self.grok_client:
            return None
        
        # ∆Øu ti√™n model m·∫°nh tr∆∞·ªõc (c·∫≠p nh·∫≠t 2026)
        if model_type == "pro":
            model_plan = ["grok-4", "grok-4-1-fast-reasoning", "grok-4-fast-reasoning"]
        else:
            model_plan = ["grok-4-1-fast-non-reasoning", "grok-4-fast-non-reasoning"]
        
        messages = []
        if system_instruction:
            messages.append({"role": "system", "content": system_instruction})
        messages.append({"role": "user", "content": prompt})
        
        for model in model_plan:
            try:
                response = self.grok_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=4000,
                    top_p=0.95
                )
                if response.choices and response.choices[0].message.content:
                    return response.choices[0].message.content.strip()
            except GrokResourceExhausted:
                st.info(f"üî∏ Grok {model}: H·∫øt quota ‚Üí th·ª≠ model nh·∫π h∆°n")
                time.sleep(5)
                continue
            except (GrokServiceUnavailable, GrokInternalServerError):
                time.sleep(3)
                continue
            except GrokBadRequest as e:
                return f"Grok prompt error: {str(e)[:200]}"
            except Exception:
                continue
        
        return None

    def generate(self, prompt, model_type="pro", system_instruction=None):
        """H√†m ch√≠nh: ∆Øu ti√™n Grok ‚Üí fallback Gemini"""
        if not self.grok_ready and not self.gemini_ready:
            return "‚ö†Ô∏è C·∫£ 2 API ƒë·ªÅu ch∆∞a s·∫µn s√†ng. Ki·ªÉm tra secrets.toml"
        
        # B∆∞·ªõc 1: Th·ª≠ Grok tr∆∞·ªõc
        if self.grok_ready:
            st.info("ü§ñ ƒêang d√πng Grok (∆∞u ti√™n)")
            grok_result = self._generate_with_grok(prompt, model_type, system_instruction)
            if grok_result:
                return grok_result
            else:
                st.warning("üîÑ Grok b·∫≠n/h·∫øt quota ‚Üí chuy·ªÉn sang Gemini")
        
        # B∆∞·ªõc 2: Fallback Gemini
        if self.gemini_ready:
            st.info("ü§ñ ƒêang d√πng Gemini (fallback)")
            gemini_result = self._generate_with_gemini(prompt, model_type, system_instruction)
            if gemini_result and "error" not in gemini_result.lower():
                return gemini_result
            else:
                return f"‚ö†Ô∏è C·∫£ Grok v√† Gemini ƒë·ªÅu l·ªói:\n- Grok: b·∫≠n/h·∫øt quota\n- Gemini: {gemini_result or 'l·ªói'}\nüí° Th·ª≠ l·∫°i sau v√†i ph√∫t nh√© ch·ªã!"
        
        return "‚ö†Ô∏è Kh√¥ng c√≥ API n√†o ho·∫°t ƒë·ªông."
