import google.generativeai as genai
import streamlit as st
import time
from google.api_core.exceptions import ResourceExhausted, ServiceUnavailable, InternalServerError, InvalidArgument

class AI_Core:
    def __init__(self):
        self.api_ready = False
        try:
            # Ki·ªÉm tra key t·ªìn t·∫°i tr∆∞·ªõc khi l·∫•y
            if "api_keys" in st.secrets and "gemini_api_key" in st.secrets["api_keys"]:
                api_key = st.secrets["api_keys"]["gemini_api_key"]
                genai.configure(api_key=api_key)
                self.api_ready = True
            else:
                st.error("‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh API Key trong secrets.toml")
                return

            # C·∫•u h√¨nh Safety (Ch·∫∑n n·ªôi dung ƒë·ªôc h·∫°i)
            self.safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
            
            # C·∫•u h√¨nh Generation Config (T·ªëi ∆∞u cho c√¢u h·ªèi)
            self.gen_config = genai.GenerationConfig(
                temperature=0.7,  # C√¢n b·∫±ng gi·ªØa s√°ng t·∫°o v√† ch√≠nh x√°c
                max_output_tokens=4000,  # ƒê·ªß cho 20 c√¢u h·ªèi
                top_p=0.95,
                top_k=40
            )

        except Exception as e:
            st.error(f"‚ùå L·ªói kh·ªüi t·∫°o AI Core: {e}")

    def _get_model(self, model_name, system_instr=None):
        """H√†m helper ƒë·ªÉ kh·ªüi t·∫°o model ƒë√∫ng phi√™n b·∫£n"""
        valid_names = {
            "flash": "gemini-2.0-flash-exp",
            "pro": "gemini-2.0-flash-exp",  # D√πng flash exp cho c·∫£ 2 (nhanh + r·∫ª)
        }
        
        target_name = valid_names.get(model_name, "gemini-2.0-flash-exp")
        
        try:
            return genai.GenerativeModel(
                model_name=target_name,
                safety_settings=self.safety_settings,
                generation_config=self.gen_config,
                system_instruction=system_instr
            )
        except Exception:
            return None

    def generate(self, prompt, model_type="flash", system_instruction=None):
        """
        H√†m g·ªçi AI ch√≠nh: T·ª± ƒë·ªông chuy·ªÉn model n·∫øu l·ªói (Fallback Strategy)
        """
        if not self.api_ready:
            return "‚ö†Ô∏è API Key ch∆∞a s·∫µn s√†ng."

        # Chi·∫øn thu·∫≠t ∆∞u ti√™n: Flash (nhanh) -> Pro (d·ª± ph√≤ng)
        plan = [
            ("flash", "Gemini 2.0 Flash Exp", 2), 
            ("pro", "Gemini 2.0 Flash Exp", 2),
        ]

        last_errors = []
        quota_exhausted_count = 0

        for m_type, m_name, base_wait_time in plan:
            try:
                # Kh·ªüi t·∫°o model
                model = self._get_model(m_type, system_instr=system_instruction)
                if not model: 
                    continue
                
                # G·ªçi API
                response = model.generate_content(prompt)
                
                # Ki·ªÉm tra k·∫øt qu·∫£
                if response and hasattr(response, 'text') and response.text:
                    return response.text
                
                # X·ª≠ l√Ω c√°c l√Ω do b·ªã ch·∫∑n (Safety, Token...)
                if response and hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    if hasattr(candidate, 'finish_reason'):
                        reason = candidate.finish_reason.name
                        if reason == "SAFETY":
                            last_errors.append(f"{m_name}: B·ªã ch·∫∑n (Safety)")
                            continue
                        elif reason == "MAX_TOKENS":
                            last_errors.append(f"{m_name}: Qu√° d√†i (Max Tokens)")
                            continue
                
                last_errors.append(f"{m_name}: Tr·∫£ v·ªÅ r·ªóng")
                continue
            
            except ResourceExhausted:
                quota_exhausted_count += 1
                error_msg = f"{m_name}: H·∫øt Quota (429)"
                last_errors.append(error_msg)
                time.sleep(base_wait_time * quota_exhausted_count)
                
            except (ServiceUnavailable, InternalServerError):
                last_errors.append(f"{m_name}: L·ªói Server (5xx)")
                time.sleep(2)
            
            except InvalidArgument as e:
                return f"‚ö†Ô∏è L·ªói Input (Prompt kh√¥ng h·ª£p l·ªá): {str(e)[:200]}"
                
            except Exception as e:
                last_errors.append(f"{m_name}: L·ªói l·∫° ({str(e)[:50]})")
                time.sleep(1)

        # N·∫øu th·ª≠ h·∫øt c√°c model m√† v·∫´n l·ªói
        error_summary = "\n".join(f"- {e}" for e in last_errors[-3:])
        return f"‚ö†Ô∏è H·ªá th·ªëng ƒëang b·∫≠n ho·∫∑c g·∫∑p l·ªói:\n{error_summary}\n\nüí° Vui l√≤ng th·ª≠ l·∫°i sau 1 ph√∫t."
