import streamlit as st
import pandas as pd
import numpy as np
from services.blocks.file_processor import doc_file, clean_pdf_text
from services.blocks.embedding_engine import load_encoder, encode_texts
from services.blocks.html_generator import load_template, create_html_block, create_interactive_html_block
from services.blocks.rag_orchestrator import analyze_document_streamlit, compute_similarity_with_excel, store_history, init_knowledge_universe, create_personal_rag
from ai_core import AI_Core
from voice_block import Voice_Engine
from prompts import DEBATE_PERSONAS, BOOK_ANALYSIS_PROMPT
import time

# âœ… IMPORT SUPABASE
try:
    from supabase import create_client, Client
except ImportError:
    # KhÃ´ng raise error trá»±c tiáº¿p Ä‘á»ƒ app váº«n cháº¡y cÃ¡c pháº§n khÃ¡c
    st.error("âš ï¸ Thiáº¿u thÆ° viá»‡n supabase. HÃ£y thÃªm 'supabase' vÃ o requirements.txt")

# ==========================================
# ğŸŒ Bá»˜ Tá»ª ÄIá»‚N ÄA NGÃ”N NGá»® (giá»¯ nguyÃªn)
# ==========================================
TRANS = {
    "vi": {
        "lang_select": "NgÃ´n ngá»¯ / Language / è¯­è¨€",
        "tab1": "ğŸ“š PhÃ¢n TÃ­ch SÃ¡ch",
        "tab2": "âœï¸ Dá»‹ch Giáº£",
        "tab3": "ğŸ—£ï¸ Tranh Biá»‡n",
        "tab4": "ğŸ™ï¸ PhÃ²ng Thu AI",
        "tab5": "â³ Nháº­t KÃ½",
        "t1_header": "Trá»£ lÃ½ NghiÃªn cá»©u & Knowledge Graph",
        "t1_up_excel": "1. Káº¿t ná»‘i Kho SÃ¡ch (Excel)",
        "t1_up_doc": "2. TÃ i liá»‡u má»›i (PDF/Docx)",
        "t1_btn": "ğŸš€ PHÃ‚N TÃCH NGAY",
        "t1_analyzing": "Äang phÃ¢n tÃ­ch {name}...",
        "t1_connect_ok": "âœ… ÄÃ£ káº¿t ná»‘i {n} cuá»‘n sÃ¡ch.",
        "t1_graph_title": "ğŸª VÅ© Trá»¥ SÃ¡ch",
        "t2_header": "Dá»‹ch Thuáº­t Äa Chiá»u",
        "t2_input": "Nháº­p vÄƒn báº£n cáº§n dá»‹ch:",
        "t2_target": "Dá»‹ch sang:",
        "t2_style": "Phong cÃ¡ch:",
        "t2_btn": "âœï¸ Dá»‹ch Ngay",
        "t3_header": "Äáº¥u TrÆ°á»ng TÆ° Duy",
        "t3_persona_label": "Chá»n Äá»‘i Thá»§:",
        "t3_input": "Nháº­p chá»§ Ä‘á» tranh luáº­n...",
        "t3_clear": "ğŸ—‘ï¸ XÃ³a Chat",
        "t4_header": "ğŸ™ï¸ PhÃ²ng Thu AI Äa NgÃ´n Ngá»¯",
        "t4_voice": "Chá»n Giá»ng:",
        "t4_speed": "Tá»‘c Ä‘á»™:",
        "t4_btn": "ğŸ”Š Táº O AUDIO",
        "t5_header": "Nháº­t KÃ½ & Lá»‹ch Sá»­",
        "t5_refresh": "ğŸ”„ Táº£i láº¡i Lá»‹ch sá»­",
        "t5_empty": "ChÆ°a cÃ³ dá»¯ liá»‡u lá»‹ch sá»­.",
    },
    "en": {
        "lang_select": "Language",
        "tab1": "ğŸ“š Book Analysis",
        "tab2": "âœï¸ Translator",
        "tab3": "ğŸ—£ï¸ Debater",
        "tab4": "ğŸ™ï¸ AI Studio",
        "tab5": "â³ History",
        "t1_header": "Research Assistant & Knowledge Graph",
        "t1_up_excel": "1. Connect Book Database (Excel)",
        "t1_btn": "ğŸš€ ANALYZE NOW",
        "t1_analyzing": "Analyzing {name}...",
        "t1_connect_ok": "âœ… Connected {n} books.",
        "t1_graph_title": "ğŸª Book Universe",
        "t2_header": "Multidimensional Translator",
        "t2_input": "Enter text to translate:",
        "t2_target": "Translate to:",
        "t2_style": "Style:",
        "t2_btn": "âœï¸ Translate",
        "t3_header": "Thinking Arena",
        "t3_persona_label": "Choose Opponent:",
        "t3_input": "Enter debate topic...",
        "t3_clear": "ğŸ—‘ï¸ Clear Chat",
        "t4_header": "ğŸ™ï¸ Multilingual AI Studio",
        "t4_voice": "Select Voice:",
        "t4_speed": "Speed:",
        "t4_btn": "ğŸ”Š GENERATE AUDIO",
        "t5_header": "Logs & History",
        "t5_refresh": "ğŸ”„ Refresh History",
        "t5_empty": "No history data found.",
    },
    "zh": {
        "lang_select": "è¯­è¨€",
        "tab1": "ğŸ“š ä¹¦ç±åˆ†æ",
        "tab2": "âœï¸ ç¿»è¯‘ä¸“å®¶",
        "tab3": "ğŸ—£ï¸ è¾©è®ºåœº",
        "tab4": "ğŸ™ï¸ AI å½•éŸ³å®¤",
        "tab5": "â³ å†å²è®°å½•",
        "t1_header": "ç ”ç©¶åŠ©æ‰‹ & çŸ¥è¯†å›¾è°±",
        "t1_up_excel": "1. è¿æ¥ä¹¦åº“ (Excel)",
        "t1_up_doc": "2. ä¸Šä¼ æ–°æ–‡æ¡£ (PDF/Docx)",
        "t1_btn": "ğŸš€ ç«‹å³åˆ†æ",
        "t1_analyzing": "æ­£åœ¨åˆ†æ {name}...",
        "t1_connect_ok": "âœ… å·²è¿æ¥ {n} æœ¬ä¹¦ã€‚",
        "t1_graph_title": "ğŸª ä¹¦ç±å®‡å®™",
        "t2_header": "å¤šç»´ç¿»è¯‘",
        "t2_input": "è¾“å…¥æ–‡æœ¬:",
        "t2_target": "ç¿»è¯‘æˆ:",
        "t2_style": "é£æ ¼:",
        "t2_btn": "âœï¸ ç¿»è¯‘",
        "t3_header": "æ€ç»´ç«æŠ€åœº",
        "t3_persona_label": "é€‰æ‹©å¯¹æ‰‹:",
        "t3_input": "è¾“å…¥è¾©è®ºä¸»é¢˜...",
        "t3_clear": "ğŸ—‘ï¸ æ¸…é™¤èŠå¤©",
        "t4_header": "ğŸ™ï¸ AI å¤šè¯­è¨€å½•éŸ³å®¤",
        "t4_voice": "é€‰æ‹©å£°éŸ³:",
        "t4_speed": "è¯­é€Ÿ:",
        "t4_btn": "ğŸ”Š ç”ŸæˆéŸ³é¢‘",
        "t5_header": "æ—¥å¿— & å†å²",
        "t5_refresh": "ğŸ”„ åˆ·æ–°å†å²",
        "t5_empty": "æš‚æ— å†å²æ•°æ®ã€‚",
    }
}

def T(key):
    lang = st.session_state.get('weaver_lang', 'vi')
    return TRANS.get(lang, TRANS['vi']).get(key, key)

# --- CÃC HÃ€M PHá»¤ TRá»¢ (giá»¯ nguyÃªn, nháº¹) ---
@st.cache_resource
def load_models():
    try:
        model = load_encoder()
        return model
    except Exception as e:
        return None

def check_model_available():
    model = load_models()
    if model is None:
        st.warning("âš ï¸ Chá»©c nÄƒng Knowledge Graph táº¡m thá»i khÃ´ng kháº£ dá»¥ng (thiáº¿u RAM)")
        return False
    return True

def doc_file_safe(uploaded_file):
    return doc_file(uploaded_file)

# --- RUN ---
def run():
    ai = AI_Core()
    voice = Voice_Engine()

    with st.sidebar:
        st.markdown("---")
        lang_choice = st.selectbox("ğŸŒ " + TRANS['vi']['lang_select'], ["Tiáº¿ng Viá»‡t", "English", "ä¸­æ–‡"], key="weaver_lang_selector")
        if lang_choice == "Tiáº¿ng Viá»‡t":
            st.session_state.weaver_lang = 'vi'
        elif lang_choice == "English":
            st.session_state.weaver_lang = 'en'
        else:
            st.session_state.weaver_lang = 'zh'

    st.header(f"ğŸ§  The Cognitive Weaver")

    tab1, tab2, tab3, tab4, tab5 = st.tabs([T("tab1"), T("tab2"), T("tab3"), T("tab4"), T("tab5")])

    # TAB 1: RAG
    with tab1:
        st.header(T("t1_header"))
        with st.container():
            c1, c2, c3 = st.columns([1, 1, 1])
            with c1:
                file_excel = st.file_uploader(T("t1_up_excel"), type="xlsx", key="t1")
            with c2:
                uploaded_files = st.file_uploader(T("t1_up_doc"), type=["pdf", "docx", "txt", "md", "html"], accept_multiple_files=True)
            with c3:
                st.write("")
                st.write("")
                btn_run = st.button(T("t1_btn"), type="primary", use_container_width=True)

        if btn_run and uploaded_files:
            vec = load_encoder()
            db_df = None
            has_db_excel = False

            if file_excel:
                try:
                    db_df = pd.read_excel(file_excel).dropna(subset=["TÃªn sÃ¡ch"])
                    has_db_excel = True
                    st.success(T("t1_connect_ok").format(n=len(db_df)))
                except Exception as e:
                    st.error(f"âŒ Lá»—i Ä‘á»c Excel: {e}")

            for f in uploaded_files:
                text = doc_file_safe(f)
                if not text:
                    st.warning(f"âš ï¸ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c file {f.name}")
                    continue

                link = ""
                if has_db_excel and db_df is not None and vec is not None:
                    try:
                        matches = compute_similarity_with_excel(text, db_df, vec)
                        if matches:
                            link = "\n".join([f"- {m[0]} ({m[1]*100:.0f}%)" for m in matches])
                    except Exception as e:
                        st.warning(f"KhÃ´ng thá»ƒ tÃ­nh similarity: {e}")

                # --- SAFE INIT: Knowledge Graph (trÃ¡nh UnboundLocalError) ---
                kg = st.session_state.get("knowledge_universe", None)
                if kg is None:
                    try:
                        kg = init_knowledge_universe()
                        st.session_state["knowledge_universe"] = kg
                    except Exception as e:
                        st.warning(f"Knowledge Graph chÆ°a khá»Ÿi táº¡o: {e}")
                        kg = None

                # Láº¥y sÃ¡ch liÃªn quan náº¿u KG kháº£ dá»¥ng
                try:
                    related = kg.find_related_books(text[:2000], top_k=3) if kg else []
                except Exception as e:
                    st.warning(f"Lá»—i khi tÃ¬m sÃ¡ch liÃªn quan: {e}")
                    related = []

                with st.spinner(T("t1_analyzing").format(name=f.name)):
                    res = analyze_document_streamlit(f.name, text, user_lang=st.session_state.get('weaver_lang', 'vi'))
                    if res and "Lá»—i" not in res:
                        st.markdown(f"### ğŸ“„ {f.name}")
                        # Hiá»ƒn thá»‹ link sÃ¡ch liÃªn quan (náº¿u cÃ³)
                        if link:
                            st.markdown("**SÃ¡ch cÃ³ liÃªn quan (tá»« Excel):**")
                            st.markdown(link)
                        # Hiá»ƒn thá»‹ káº¿t quáº£ phÃ¢n tÃ­ch
                        st.markdown(res)
                        # Náº¿u cÃ³ KG liÃªn quan, hiá»ƒn thá»‹ tÃ³m táº¯t
                        if related:
                            st.markdown("**SÃ¡ch liÃªn quan tá»« Knowledge Graph:**")
                            for node_id, title, score, explanation in related:
                                st.markdown(f"- **{title}** ({score:.2f}) â€” {explanation}")
                        st.markdown("---")
                        store_history("PhÃ¢n TÃ­ch SÃ¡ch", f.name, res[:500])
                    else:
                        st.error(f"âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch file {f.name}: {res}")

    # === TAB 2: Dá»ŠCH GIáº¢ ===
    with tab2:
        st.subheader(T("t2_header"))
        txt = st.text_area(T("t2_input"), height=150, key="w_t2_inp")
        c_l, c_s, c_b = st.columns([1, 1, 1])
        with c_l:
            target_lang = st.selectbox(T("t2_target"), ["Tiáº¿ng Viá»‡t", "English", "Chinese", "French", "Japanese"], key="w_t2_lang")
        with c_s:
            style = st.selectbox(T("t2_style"), ["Default", "Academic", "Literary", "Business"], key="w_t2_style")
        if st.button(T("t2_btn"), key="w_t2_btn") and txt:
            with st.spinner("AI Translating..."):
                p = f"Translate to {target_lang}. Style: {style}. Text: {txt}"
                res = ai.generate(p, model_type="pro")
                st.markdown(res)
                store_history("Dá»‹ch Thuáº­t", f"{target_lang}", txt[:50])

    # === TAB 3: Äáº¤U TRÆ¯á»œNG ===
    with tab3:
        st.subheader(T("t3_header"))
        mode = st.radio("Mode:", ["ğŸ‘¤ Solo", "âš”ï¸ Multi-Agent"], horizontal=True, key="w_t3_mode")
        if "weaver_chat" not in st.session_state:
            st.session_state.weaver_chat = []

        if mode == "ğŸ‘¤ Solo":
            c1, c2 = st.columns([3, 1])
            with c1:
                persona = st.selectbox(T("t3_persona_label"), list(DEBATE_PERSONAS.keys()), key="w_t3_solo_p")
            with c2:
                if st.button(T("t3_clear"), key="w_t3_clr"):
                    st.session_state.weaver_chat = []
                    st.rerun()
            for msg in st.session_state.weaver_chat:
                st.chat_message(msg["role"]).write(msg["content"])
            if prompt := st.chat_input(T("t3_input")):
                st.chat_message("user").write(prompt)
                st.session_state.weaver_chat.append({"role": "user", "content": prompt})
                recent_history = st.session_state.weaver_chat[-10:]
                context_text = "\n".join([f"{m['role'].upper()}: {m['content']}" for m in recent_history])
                full_prompt = f"Lá»ŠCH Sá»¬:\n{context_text}\n\nNHIá»†M Vá»¤: Tráº£ lá»i cÃ¢u há»i má»›i nháº¥t cá»§a USER."
                with st.chat_message("assistant"):
                    with st.spinner("..."):
                        res = ai.generate(full_prompt, model_type="flash", system_instruction=DEBATE_PERSONAS[persona])
                        if res:
                            st.write(res)
                            st.session_state.weaver_chat.append({"role": "assistant", "content": res})
                            store_history("Tranh Biá»‡n Solo", f"{persona} - {prompt[:50]}...", f"Q: {prompt}\nA: {res}")
        else:
            participants = st.multiselect("Chá»n Há»™i Äá»“ng:", list(DEBATE_PERSONAS.keys()),
                                          default=[list(DEBATE_PERSONAS.keys())[0], list(DEBATE_PERSONAS.keys())[1]],
                                          max_selections=3)
            topic = st.text_input("Chá»§ Ä‘á»:", key="w_t3_topic")
            if st.button("ğŸ”¥ KHAI CHIáº¾N", disabled=(len(participants) < 2 or not topic)):
                st.session_state.weaver_chat = []
                start_msg = f"ğŸ“¢ **CHá»¦ Tá»ŒA:** Khai máº¡c tranh luáº­n vá»: *'{topic}'*"
                st.session_state.weaver_chat.append({"role": "system", "content": start_msg})
                st.info(start_msg)
                full_transcript = [start_msg]

                MAX_DEBATE_TIME = 600
                start_time = time.time()

                with st.status("ğŸ”¥ Cuá»™c chiáº¿n Ä‘ang diá»…n ra (3 vÃ²ng)...") as status:
                    try:
                        for round_num in range(1, 4):
                            if time.time() - start_time > MAX_DEBATE_TIME:
                                st.warning("â° Háº¿t giá»! Cuá»™c tranh luáº­n káº¿t thÃºc sá»›m.")
                                break

                            status.update(label=f"ğŸ”„ VÃ²ng {round_num}/3 Ä‘ang diá»…n ra...")

                            for i, p_name in enumerate(participants):
                                if time.time() - start_time > MAX_DEBATE_TIME:
                                    break

                                context_str = topic
                                if len(st.session_state.weaver_chat) > 1:
                                    recent_msgs = st.session_state.weaver_chat[-4:]
                                    context_str = "\n".join([f"{m['role']}: {m['content']}" for m in recent_msgs])

                                length_instruction = " (Báº®T BUá»˜C: Tráº£ lá»i ngáº¯n gá»n khoáº£ng 150-200 tá»«. Äi tháº³ng vÃ o trá»ng tÃ¢m, khÃ´ng lan man.)"

                                if round_num == 1:
                                    p_prompt = f"CHá»¦ Äá»€: {topic}\nNHIá»†M Vá»¤ (VÃ²ng 1 - Má»Ÿ Ä‘áº§u): NÃªu quan Ä‘iá»ƒm chÃ­nh vÃ  2-3 lÃ½ láº½. {length_instruction}"
                                else:
                                    p_prompt = f"CHá»¦ Äá»€: {topic}\nBá»I Cáº¢NH Má»šI NHáº¤T:\n{context_str}\n\nNHIá»†M Vá»¤ (VÃ²ng {round_num} - Pháº£n biá»‡n): Pháº£n biá»‡n sáº¯c bÃ©n quan Ä‘iá»ƒm Ä‘á»‘i thá»§ vÃ  cá»§ng cá»‘ láº­p trÆ°á»ng cá»§a mÃ¬nh. {length_instruction}"

                                try:
                                    res = ai.generate(
                                        p_prompt,
                                        model_type="pro",
                                        system_instruction=DEBATE_PERSONAS[p_name]
                                    )

                                    if res:
                                        clean_res = res.replace(f"{p_name}:", "").strip()
                                        clean_res = clean_res.replace(f"**{p_name}:**", "").strip()
                                        icons = {"Káº» Pháº£n Biá»‡n": "ğŸ˜ˆ", "Shushu": "ğŸ©", "Pháº­t Tá»•": "ğŸ™", "Socrates": "ğŸ›ï¸"}
                                        icon = icons.get(p_name, "ğŸ¤–")
                                        content_fmt = f"### {icon} {p_name}\n\n{clean_res}"
                                        st.session_state.weaver_chat.append({"role": "assistant", "content": content_fmt})
                                        full_transcript.append(content_fmt)
                                        with st.chat_message("assistant", avatar=icon):
                                            st.markdown(content_fmt)
                                        time.sleep(1)
                                except Exception as e:
                                    st.error(f"Lá»—i khi gá»i AI cho {p_name}: {e}")
                                    continue
                        status.update(label="âœ… Tranh luáº­n káº¿t thÃºc!", state="complete")
                    except Exception as e:
                        st.error(f"Lá»—i trong quÃ¡ trÃ¬nh tranh luáº­n: {e}")

                full_log = "\n\n".join(full_transcript)
                store_history("Há»™i Äá»“ng Tranh Biá»‡n", f"Chá»§ Ä‘á»: {topic}", full_log)

    # === TAB 4: PHÃ’NG THU ===
    with tab4:
        st.subheader(T("t4_header"))
        inp_v = st.text_area("Text:", height=200)
        btn_v = st.button(T("t4_btn"))
        if btn_v and inp_v:
            path = voice.speak(inp_v)
            if path:
                st.audio(path)

    # === TAB 5: NHáº¬T KÃ (CÃ“ PHáº¦N BAYES) ===
    with tab5:
        st.subheader("â³ Nháº­t KÃ½ & Pháº£n Chiáº¿u TÆ° Duy")
        if st.button("ğŸ”„ Táº£i láº¡i", key="w_t5_refresh"):
            from services.blocks.rag_orchestrator import DBBlock, tai_lich_su
            db = DBBlock()
            st.session_state.history_cloud = tai_lich_su()
            st.rerun()

        data = st.session_state.get("history_cloud", [])
        if data:
            df_h = pd.DataFrame(data)
            if "SentimentScore" in df_h.columns:
                try:
                    df_h["score"] = pd.to_numeric(df_h["SentimentScore"], errors='coerce').fillna(0)
                    import plotly.express as px
                    fig = px.line(df_h, x="Time", y="score", markers=True, color_discrete_sequence=["#76FF03"])
                    st.plotly_chart(fig, use_container_width=True)
                except:
                    pass

            with st.expander("ğŸ”® PhÃ¢n tÃ­ch TÆ° duy theo xÃ¡c suáº¥t Bayes (E.T. Jaynes)", expanded=False):
                st.info("AI sáº½ coi Lá»‹ch sá»­ hoáº¡t Ä‘á»™ng cá»§a chá»‹ lÃ  'Dá»¯ liá»‡u quan sÃ¡t' (Evidence) Ä‘á»ƒ suy luáº­n ra 'HÃ m má»¥c tiÃªu' (Objective Function) vÃ  sá»± dá»‹ch chuyá»ƒn niá»m tin cá»§a chá»‹.")
                if st.button("ğŸ§  Cháº¡y MÃ´ hÃ¬nh Bayes ngay"):
                    with st.spinner("Äang tÃ­nh toÃ¡n xÃ¡c suáº¥t háº­u nghiá»‡m (Posterior)..."):
                        recent_logs = df_h.tail(10).to_dict(orient="records")
                        logs_text = pd.io.json.dumps(recent_logs, ensure_ascii=False)
                        bayes_prompt = f"""
                        ÄÃ³ng vai má»™t nhÃ  khoa há»c tÆ° duy theo trÆ°á»ng phÃ¡i E.T. Jaynes (sÃ¡ch 'Probability Theory: The Logic of Science').

                        Dá»® LIá»†U QUAN SÃT (EVIDENCE):
                        ÄÃ¢y lÃ  nháº­t kÃ½ hoáº¡t Ä‘á»™ng cá»§a tÃ´i:
                        {logs_text}

                        NHIá»†M Vá»¤:
                        HÃ£y phÃ¢n tÃ­ch chuá»—i hÃ nh Ä‘á»™ng nÃ y nhÆ° má»™t bÃ i toÃ¡n suy luáº­n Bayes.
                        1. **XÃ¡c Ä‘á»‹nh Priors (Niá»m tin tiÃªn nghiá»‡m):** Dá»±a trÃªn cÃ¡c hÃ nh Ä‘á»™ng Ä‘áº§u, tÃ´i Ä‘ang quan tÃ¢m/tin tÆ°á»Ÿng Ä‘iá»u gÃ¬?
                        2. **Cáº­p nháº­t Likelihood (Kháº£ nÄƒng):** CÃ¡c hÃ nh Ä‘á»™ng tiáº¿p theo cá»§ng cá»‘ hay lÃ m yáº¿u Ä‘i niá»m tin Ä‘Ã³?
                        3. **Káº¿t luáº­n Posterior (Háº­u nghiá»‡m):** Tráº¡ng thÃ¡i tÆ° duy hiá»‡n táº¡i cá»§a tÃ´i Ä‘ang há»™i tá»¥ vá» Ä‘Ã¢u? CÃ³ mÃ¢u thuáº«n (Inconsistency) nÃ o trong logic hÃ nh Ä‘á»™ng khÃ´ng?

                        Tráº£ lá»i ngáº¯n gá»n, sÃ¢u sáº¯c, dÃ¹ng thuáº­t ngá»¯ xÃ¡c suáº¥t nhÆ°ng dá»… hiá»ƒu.
                        """
                        analysis = ai.generate(bayes_prompt, model_type="pro")
                        st.markdown(analysis)

            st.divider()
            for index, item in df_h.iterrows():
                t = str(item.get('Time', ''))
                tp = str(item.get('Type', ''))
                ti = str(item.get('Title', ''))
                ct = str(item.get('Content', ''))
                icon = "ğŸ“"
                if "Tranh Biá»‡n" in tp:
                    icon = "ğŸ—£ï¸"
                elif "Dá»‹ch" in tp:
                    icon = "âœï¸"
                with st.expander(f"{icon} {t} | {tp} | {ti}"):
                    st.markdown(ct)
        else:
            st.info(T("t5_empty"))
