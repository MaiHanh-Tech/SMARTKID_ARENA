import streamlit as st
import pandas as pd
import numpy as np
from services.blocks.file_processor import doc_file, clean_pdf_text
from services.blocks.embedding_engine import load_encoder, encode_texts
from services.blocks.html_generator import load_template, create_html_block, create_interactive_html_block
from services.blocks.rag_orchestrator import analyze_document_streamlit, compute_similarity_with_excel, store_history, init_knowledge_universe, create_personal_rag
from ai_core import AI_Core
from voice_block import Voice_Engine
from prompts import DEBATE_PERSONAS, BOOK_ANALYSIS_PROMPT
import time

def run():
    ai = AI_Core()
    voice = Voice_Engine()
    st.header("üß† The Cognitive Weaver")

    with st.sidebar:
        st.markdown("---")
        lang_choice = st.selectbox("üåê Ng√¥n ng·ªØ", ["Ti·∫øng Vi·ªát", "English", "‰∏≠Êñá"], key="weaver_lang_selector")
        if lang_choice == "Ti·∫øng Vi·ªát": st.session_state.weaver_lang = 'vi'
        elif lang_choice == "English": st.session_state.weaver_lang = 'en'
        else: st.session_state.weaver_lang = 'zh'

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìö Book Analysis", "‚úçÔ∏è Translator", "üó£Ô∏è Debater", "üéôÔ∏è AI Studio", "‚è≥ History"])

    # TAB 1: RAG / Book analysis
    with tab1:
        st.header("Research Assistant & Knowledge Graph")
        c1, c2, c3 = st.columns([1,1,1])
        with c1:
            file_excel = st.file_uploader("1. Connect Book Database (Excel)", type="xlsx", key="t1")
        with c2:
            uploaded_files = st.file_uploader("2. New Documents (PDF/Docx)", type=["pdf","docx","txt","md","html"], accept_multiple_files=True)
        with c3:
            btn_run = st.button("üöÄ ANALYZE NOW", type="primary", use_container_width=True)

        if btn_run and uploaded_files:
            vec = load_encoder()
            db_df = None
            if file_excel:
                try:
                    db_df = pd.read_excel(file_excel).dropna(subset=["T√™n s√°ch"])
                    st.success(f"‚úÖ Connected {len(db_df)} books.")
                except Exception as e:
                    st.error(f"‚ùå L·ªói ƒë·ªçc Excel: {e}")

            for f in uploaded_files:
                text = doc_file(f)
                if not text:
                    st.warning(f"‚ö†Ô∏è Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file {f.name}")
                    continue

                # similarity check
                link = ""
                if db_df is not None and vec is not None:
                    try:
                        matches = compute_similarity_with_excel(text, db_df, vec)
                        if matches:
                            link = "\n".join([f"- {m[0]} ({m[1]*100:.0f}%)" for m in matches])
                    except Exception as e:
                        st.warning(f"Kh√¥ng th·ªÉ t√≠nh similarity: {e}")

                with st.spinner(f"Analyzing {f.name}..."):
                    res = analyze_document_streamlit(f.name, text, user_lang=st.session_state.get('weaver_lang','vi'))
                    if res and "L·ªói" not in res:
                        st.markdown(f"### üìÑ {f.name}")
                        st.markdown(res)
                        st.markdown("---")
                        store_history("Ph√¢n T√≠ch S√°ch", f.name, res[:500])
                    else:
                        st.error(f"‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch file {f.name}: {res}")

    # TAB 2: Translator (delegated to module_translator UI) - keep simple link / integration
    with tab2:
        st.subheader("Translator (Use dedicated module)")
        st.info("Ch·ªçn 'AI Translator' t·ª´ sidebar ƒë·ªÉ m·ªü ch·ª©c nƒÉng d·ªãch chuy√™n s√¢u.")

    # TAB 3: Debater (Solo)
    with tab3:
        st.subheader("Thinking Arena (Solo)")
        if "weaver_chat" not in st.session_state: st.session_state.weaver_chat = []
        persona = st.selectbox("Ch·ªçn nh√¢n c√°ch:", list(DEBATE_PERSONAS.keys()))
        if st.button("üóëÔ∏è Clear Chat"):
            st.session_state.weaver_chat = []; st.rerun()
        for msg in st.session_state.weaver_chat:
            st.chat_message(msg["role"]).write(msg["content"])
        if prompt := st.chat_input("Enter debate topic..."):
            st.chat_message("user").write(prompt)
            st.session_state.weaver_chat.append({"role":"user","content":prompt})
            context_text = "\n".join([f"{m['role'].upper()}: {m['content']}" for m in st.session_state.weaver_chat[-10:]])
            full_prompt = f"L·ªäCH S·ª¨:\n{context_text}\n\nNHI·ªÜM V·ª§: Tr·∫£ l·ªùi c√¢u h·ªèi m·ªõi nh·∫•t c·ªßa USER."
            with st.chat_message("assistant"):
                with st.spinner("..."):
                    res = ai.generate(full_prompt, model_type="flash", system_instruction=DEBATE_PERSONAS[persona])
                    if res:
                        st.write(res)
                        st.session_state.weaver_chat.append({"role":"assistant","content":res})
                        store_history("Tranh Bi·ªán Solo", f"{persona} - {prompt[:50]}...", f"Q:{prompt}\nA:{res}")

    # TAB 4: AI Studio (Voice)
    with tab4:
        st.subheader("AI Studio")
        inp_v = st.text_area("Text:", height=200)
        if st.button("üîä GENERATE AUDIO") and inp_v:
            path = voice.speak(inp_v)
            if path: st.audio(path)

    # TAB 5: History + Personal RAG demo
    with tab5:
        st.subheader("Logs & History")
        if st.button("üîÑ Refresh History"):
            # load via rag_orchestrator db helper
            from services.blocks.db_block import DBBlock
            db = DBBlock()
            st.session_state.history_cloud = db.get_history()
            st.rerun()
        data = st.session_state.get("history_cloud", [])
        if data:
            df_h = pd.DataFrame(data)
            st.dataframe(df_h.head(50))
        else:
            st.info("No history data found.")

        st.divider()
        # Personal RAG demo (if supabase configured)
        try:
            from services.blocks.db_block import DBBlock
            db = DBBlock()
            if db.connected:
                user_id = st.session_state.get("current_user", "Unknown")
                pr = create_personal_rag(db.client, user_id)
                if st.button("üîÑ C·∫≠p nh·∫≠t Profile (ph√¢n t√≠ch l·∫°i l·ªãch s·ª≠)"):
                    pr.update_profile(force=True)
                st.expander("üìä Profile hi·ªán t·∫°i").write(pr.profile)
                st.markdown("üé≠ Try AI mimic me:")
                test_query = st.text_area("ƒê·∫∑t m·ªôt c√¢u h·ªèi", height=100)
                if st.button("üöÄ Ch·∫°y (M√¥ ph·ªèng b·∫°n)") and test_query:
                    context = pr.get_personalized_context(test_query, top_k=3)
                    persona_prompt = pr.generate_persona_prompt()
                    full_prompt = f"{context}\n=== NHI·ªÜM V·ª§ ===\nC√¢u h·ªèi: {test_query}"
                    response = ai.generate(full_prompt, model_type="pro", system_instruction=persona_prompt)
                    st.markdown("### ü§ñ AI m√¥ ph·ªèng b·∫°n:")
                    st.markdown(response)
                    pr.record_interaction("query", test_query, {"ai_response": response})
            else:
                st.info("C·∫ßn k·∫øt n·ªëi Supabase ƒë·ªÉ d√πng t√≠nh nƒÉng n√†y")
        except Exception:
            st.info("Personal RAG kh√¥ng kh·∫£ d·ª•ng (Supabase API missing).")
