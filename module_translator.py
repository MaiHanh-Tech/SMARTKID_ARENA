import streamlit as st
import streamlit.components.v1 as components
import time
import json
import numpy as np
from typing import Optional

# ===== IMPORTS BLOCKS (with fallback) =====
try:
    from services.blocks.rag_orchestrator import get_translation_orchestrator
    HAS_ORCHESTRATOR = True  # ‚úÖ FIX 1: Th√™m d√≤ng n√†y
except ImportError:
    HAS_ORCHESTRATOR = False
    # Ch·∫°y y√™n l·∫∑ng, kh√¥ng warning

try:
    from services.blocks.text_processor import get_text_processor  # ‚úÖ FIX 2: S·ª≠a path
    HAS_TEXT_PROCESSOR = True
except ImportError:
    HAS_TEXT_PROCESSOR = False

try:
    from services.blocks.embedding_engine import load_encoder
    from sklearn.metrics.pairwise import cosine_similarity
except ImportError:
    def load_encoder(): return None
    cosine_similarity = None

# Fallback: AI Core n·∫øu kh√¥ng c√≥ orchestrator
from ai_core import AI_Core

# ===== CONSTANTS =====
LANGUAGES = {
    "Vietnamese": "Ti·∫øng Vi·ªát",
    "English": "English",
    "Chinese": "‰∏≠Êñá",
    "French": "Fran√ßais",
    "Japanese": "Êó•Êú¨Ë™û",
    "Korean": "ÌïúÍµ≠Ïñ¥"
}

STYLE_OPTIONS = {
    "VƒÉn h·ªçc": "Write in a literary style with rich imagery and elegant phrasing.",
    "Khoa h·ªçc": "Write in a scientific/technical style, precise and formal.",
    "ƒê·ªùi th∆∞·ªùng": "Write in a casual, conversational everyday style.",
    "H√†n l√¢m": "Write in an academic style with formal tone.",
    "Th∆∞∆°ng m·∫°i": "Write in a business style, concise and professional."
}

# ===== NEW CLASSES & FUNCTIONS (BLOCK 3 REQUESTS) =====

class TranslationMemory:
    """
    L∆∞u c√°c c·∫∑p (source, target) ƒë√£ d·ªãch
    Khi g·∫∑p l·∫°i c√¢u t∆∞∆°ng t·ª± -> T√°i s·ª≠ d·ª•ng
    """
    
    def __init__(self, db_client=None):
        self.db = db_client
        self.encoder = load_encoder()
        self.local_cache = {}  # In-memory cache
    
    def find_similar_segments(self, source_text, threshold=0.9):
        """
        T√¨m c√°c ƒëo·∫°n ƒë√£ d·ªãch t∆∞∆°ng t·ª± trong DB
        """
        if not self.encoder or cosine_similarity is None:
            return []
        
        try:
            query_emb = self.encoder.encode([source_text])[0]
            matches = []

            # 1. Check Local Cache
            for k, v in self.local_cache.items():
                if "embedding" in v:
                    sim = cosine_similarity([query_emb], [v["embedding"]])[0][0]
                    if sim > threshold:
                        matches.append({
                            "source": k,
                            "target": v["target"],
                            "similarity": float(sim),
                            "origin": "cache"
                        })

            # 2. Query DB (n·∫øu c√≥ connection)
            if self.db:
                try:
                    records = self.db.table("translation_memory").select("*").limit(10).execute()
                    for rec in records.data:
                        stored_emb = json.loads(rec["embedding"])
                        sim = cosine_similarity([query_emb], [stored_emb])[0][0]
                        
                        if sim > threshold:
                            matches.append({
                                "source": rec["source_text"],
                                "target": rec["target_text"],
                                "similarity": float(sim),
                                "origin": "db"
                            })
                except Exception:
                    pass
            
            return sorted(matches, key=lambda x: x["similarity"], reverse=True)
        except Exception:
            return []
    
    def store_translation(self, source, target, source_lang, target_lang):
        """L∆∞u translation v√†o memory"""
        if not self.encoder:
            return
        
        try:
            emb = self.encoder.encode([source])[0]
            
            # Save to local
            self.local_cache[source] = {
                "target": target,
                "source_lang": source_lang,
                "target_lang": target_lang,
                "embedding": emb
            }
            
            # Save to DB
            if self.db:
                data = {
                    "source_text": source,
                    "target_text": target,
                    "source_lang": source_lang,
                    "target_lang": target_lang,
                    "embedding": json.dumps(emb.tolist())
                }
                self.db.table("translation_memory").insert(data).execute()
        except Exception:
            pass

def assess_translation_quality(ai_core, source, translation, target_lang, source_lang):
    """
    [Inference] ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªãch b·∫±ng back-translation
    """
    try:
        # Back-translate
        prompt = f"Translate the following text from {target_lang} back to {source_lang}. Text: {translation}"
        back_translated = ai_core.generate(prompt, model_type="flash")
        
        # Compare
        encoder = load_encoder()
        if encoder and cosine_similarity is not None:
            embs = encoder.encode([source, back_translated])
            sim = cosine_similarity([embs[0]], [embs[1]])[0][0]
            
            quality = "Xu·∫•t s·∫Øc (Excellent)" if sim > 0.85 else "T·ªët (Good)" if sim > 0.7 else "Trung b√¨nh (Fair)"
            
            return {
                "quality": quality,
                "score": float(sim),
                "back_translation": back_translated
            }
    except Exception:
        pass
    
    return {"quality": "Unknown", "score": 0.0, "back_translation": ""}

# ===== MAIN FUNCTION =====
def run():
    """
    H√†m ch√≠nh ƒë·ªÉ app.py g·ªçi
    """
    
    st.header("üåè AI Translator Pro")
    st.caption("D·ªãch vƒÉn b·∫£n ƒëa ng√¥n ng·ªØ v·ªõi nhi·ªÅu phong c√°ch")

    # Init Translation Memory
    tm = TranslationMemory(st.session_state.get("supabase_client"))
    
    # ========== CONFIGURATION ==========
    st.subheader("‚öôÔ∏è C·∫•u h√¨nh")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        source_lang = st.selectbox(
            "Ng√¥n ng·ªØ ngu·ªìn:",
            ["Chinese", "English", "Vietnamese"],
            index=0,
            help="Ng√¥n ng·ªØ c·ªßa vƒÉn b·∫£n g·ªëc"
        )
    
    with col2:
        target_lang = st.selectbox(
            "Ng√¥n ng·ªØ ƒë√≠ch:",
            list(LANGUAGES.keys()),
            index=0,
            help="Ng√¥n ng·ªØ mu·ªën d·ªãch sang"
        )
    
    with col3:
        style = st.selectbox(
            "Phong c√°ch d·ªãch:",
            list(STYLE_OPTIONS.keys()),
            index=0,
            help="Ch·ªçn phong c√°ch vƒÉn phong"
        )
    
    # Mode selection
    if source_lang == "Chinese":
        mode = st.radio(
            "Ch·∫ø ƒë·ªô d·ªãch:",
            ["Standard (D·ªãch c√¢u)", "Interactive (H·ªçc t·ª´)"],
            horizontal=True,
            help="Standard: D·ªãch c·∫£ ƒëo·∫°n. Interactive: Hover ƒë·ªÉ xem nghƒ©a t·ª´ng t·ª´ (ch·ªâ Chinese)"
        )
    else:
        mode = "Standard (D·ªãch c√¢u)"
        if source_lang == "English":
            st.info("üí° Ch·∫ø ƒë·ªô Interactive ch·ªâ h·ªó tr·ª£ ngu·ªìn Ti·∫øng Trung")
    
    include_english = st.checkbox(
        "üìñ K√®m Ti·∫øng Anh",
        value=True,
        help="Hi·ªÉn th·ªã th√™m b·∫£n d·ªãch Ti·∫øng Anh ƒë·ªÉ ƒë·ªëi chi·∫øu (gi√∫p h·ªçc ng√¥n ng·ªØ)"
    )
    
    st.divider()
    
    # ========== INPUT ==========
    st.subheader("üìù Nh·∫≠p vƒÉn b·∫£n")
    
    text_input = st.text_area(
        "D√°n vƒÉn b·∫£n c·∫ßn d·ªãch:",
        height=250,
        placeholder="Nh·∫≠p ho·∫∑c d√°n vƒÉn b·∫£n v√†o ƒë√¢y...",
        help="H·ªó tr·ª£ vƒÉn b·∫£n d√†i, t·ª± ƒë·ªông chia chunks"
    )

    # Check TM Suggestions
    if text_input and len(text_input) > 5:
        similar_segs = tm.find_similar_segments(text_input)
        if similar_segs:
            with st.expander(f"üí° T√¨m th·∫•y {len(similar_segs)} b·∫£n d·ªãch t∆∞∆°ng t·ª± trong b·ªô nh·ªõ (TM)", expanded=False):
                for seg in similar_segs[:2]:
                    st.markdown(f"**Ngu·ªìn:** {seg['source']}")
                    st.markdown(f"**B·∫£n d·ªãch c≈©:** {seg['target']}")
                    st.caption(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng: {seg['similarity']*100:.1f}% ({seg['origin']})")
                    if st.button("D√πng b·∫£n d·ªãch n√†y", key=f"use_tm_{seg['similarity']}"):
                        st.session_state.temp_tm_result = seg['target']

    # ========== COST ESTIMATION ==========
    if text_input and HAS_TEXT_PROCESSOR:
        text_proc = get_text_processor()
        cost_info = text_proc.estimate_translation_cost(
            text_input,
            include_english,
            target_lang
        )
        
        col_info1, col_info2, col_info3 = st.columns(3)
        col_info1.metric("S·ªë k√Ω t·ª±", f"{cost_info['total_chars']:,}")
        col_info2.metric("S·ªë ƒëo·∫°n", cost_info['num_chunks'])
        col_info3.metric("API calls", cost_info['estimated_api_calls'])
        
        if cost_info.get('warning'):
            st.warning(cost_info['warning'])
    
    st.divider()
    
    # ========== TRANSLATE BUTTON ==========
    if st.button("üöÄ D·ªãch Ngay", type="primary", use_container_width=True):
        
        # Validate input
        if not text_input.strip():
            st.error("‚ùå Ch∆∞a nh·∫≠p vƒÉn b·∫£n!")
            return
        
        # Validate mode
        if mode == "Interactive (H·ªçc t·ª´)" and source_lang != "Chinese":
            st.error("‚ùå Ch·∫ø ƒë·ªô Interactive ch·ªâ h·ªó tr·ª£ ngu·ªìn Ti·∫øng Trung")
            return
        
        # ========== TRANSLATION PROCESS ==========
        progress_bar = st.progress(0, text="ƒêang kh·ªüi ƒë·ªông...")
        status_text = st.empty()
        
        html_output = None
        translated_text = None
        ai_instance_for_qa = AI_Core() # Init AI for QA later
        
        try:
            if HAS_ORCHESTRATOR:
                # ===== USE ORCHESTRATOR (Preferred) =====
                orch = get_translation_orchestrator()
                
                if mode == "Interactive (H·ªçc t·ª´)":
                    status_text.text("üîÑ ƒêang ph√¢n t√≠ch t·ª´ v·ª±ng...")
                    html_output = orch.translate_interactive(
                        text_input,
                        source_lang,
                        target_lang
                    )
                else:  # Standard mode
                    status_text.text("üîÑ ƒêang d·ªãch vƒÉn b·∫£n...")
                    def update_progress(value):
                        progress_bar.progress(value, text=f"üîÑ ƒêang d·ªãch... {int(value*100)}%")
                    
                    html_output = orch.translate_document(
                        text_input,
                        source_lang,
                        target_lang,
                        include_english,
                        progress_callback=update_progress
                    )
            
            else:
                # ===== FALLBACK: Direct AI Call =====
                status_text.text("üîÑ ƒêang d·ªãch (ch·∫ø ƒë·ªô fallback)...")
                
                style_instr = STYLE_OPTIONS.get(style, "")
                prompt = f"""Translate the following text into {LANGUAGES[target_lang]}.
Style instructions: {style_instr}

Text:
{text_input}"""
                
                translated_text = ai_instance_for_qa.generate(prompt, model_type="pro")
                tm.store_translation(text_input, translated_text, source_lang, target_lang)
                
                # Create simple HTML
                html_output = f"""<!DOCTYPE html>
<html lang="{target_lang.lower()[:2]}">
<head>
    <meta charset="UTF-8">
    <title>Translation - {style}</title>
    <style>
        body {{ font-family: Arial, sans-serif; padding: 20px; max-width: 900px; margin: 0 auto; }}
        h2 {{ color: #333; }}
        .translation {{ background: #f5f5f5; padding: 20px; border-radius: 8px; }}
    </style>
</head>
<body>
    <h2>Translation: {source_lang} ‚Üí {LANGUAGES[target_lang]}</h2>
    <p><strong>Style:</strong> {style}</p>
    <div class="translation">{translated_text}</div>
</body>
</html>"""
            
            # ========== SUCCESS ==========
            progress_bar.progress(1.0, text="‚úÖ Ho√†n th√†nh!")
            status_text.success("üéâ D·ªãch xong! Cu·ªôn xu·ªëng ƒë·ªÉ xem k·∫øt qu·∫£.")
            
            st.balloons()
            
            # ========== DOWNLOAD BUTTON ==========
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"translation_{source_lang}_to_{target_lang}_{style.replace(' ', '_')}_{timestamp}.html"
            
            st.download_button(
                label="üì• T·∫£i file HTML",
                data=html_output.encode('utf-8'),
                file_name=filename,
                mime="text/html",
                use_container_width=True
            )
            
            # ========== DISPLAY RESULTS ==========
            st.divider()
            st.subheader("üìÑ K·∫øt qu·∫£ d·ªãch thu·∫≠t")
            
            # Show HTML preview
            with st.expander("üîç Xem tr∆∞·ªõc HTML (Click ƒë·ªÉ m·ªü)", expanded=True):
                components.html(html_output, height=600, scrolling=True)

            # ========== QUALITY ASSESSMENT (New Feature) ==========
            if translated_text: # Ch·ªâ ch·∫°y khi c√≥ plain text (Fallback mode)
                st.divider()
                st.subheader("üîç ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng (AI QA)")
                with st.spinner("ƒêang th·ª±c hi·ªán Back-Translation ƒë·ªÉ ki·ªÉm tra ch·∫•t l∆∞·ª£ng..."):
                    qa_result = assess_translation_quality(
                        ai_instance_for_qa, 
                        text_input, 
                        translated_text, 
                        target_lang,
                        source_lang
                    )
                    
                    if qa_result["quality"] != "Unknown":
                        col_q1, col_q2 = st.columns([1, 3])
                        col_q1.metric("Ch·∫•t l∆∞·ª£ng", qa_result["quality"], f"{qa_result['score']*100:.1f}%")
                        with col_q2:
                            st.info(f"**Back-translation (D·ªãch ng∆∞·ª£c):**\n{qa_result['back_translation']}")
                            st.caption("N·∫øu b·∫£n d·ªãch ng∆∞·ª£c gi·ªØ nguy√™n √Ω nghƒ©a c·ªßa b·∫£n g·ªëc, b·∫£n d·ªãch c√≥ ƒë·ªô tin c·∫≠y cao.")
            
            # ========== SAVE HISTORY (Optional) =====
            try:
                from services.blocks.rag_orchestrator import store_history
                store_history(
                    "D·ªãch Thu·∫≠t",
                    f"{source_lang} ‚Üí {target_lang} ({style})",
                    text_input[:500]
                )
            except Exception:
                pass
        
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"‚ùå L·ªói d·ªãch thu·∫≠t: {str(e)}")
            with st.expander("üîç Chi ti·∫øt l·ªói (cho developer)"):
                st.exception(e)

def _estimate_api_calls(text: str, include_english: bool, target_lang: str) -> dict:
    """
    [Inference] ∆Ø·ªõc t√≠nh API calls khi kh√¥ng c√≥ text_processor
    """
    char_count = len(text.replace(" ", ""))
    num_chunks = max(1, char_count // 1500)
    api_calls = num_chunks
    if include_english and target_lang != "English":
        api_calls *= 2
    
    return {
        "total_chars": char_count,
        "num_chunks": num_chunks,
        "estimated_api_calls": api_calls,
        "warning": "‚ö†Ô∏è VƒÉn b·∫£n d√†i, c√≥ th·ªÉ t·ªën th·ªùi gian" if api_calls > 20 else None
    }
